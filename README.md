ğŸŒ± API para anÃ¡lise e otimizaÃ§Ã£o sustentÃ¡vel de prompts de IA

Este backend foi desenvolvido em FastAPI e utiliza o modelo Gemini 2.5 Flash para analisar prompts, identificar partes desnecessÃ¡rias, otimizar o texto e calcular o consumo ambiental estimado em Ã¡gua e energia baseado na quantidade de tokens.

Ele tambÃ©m possui um sistema de mÃ©tricas, contabilizando:

Tokens antes e depois

Ãgua gasta (ml)

Energia gasta (Wh)

Economia total apÃ³s otimizaÃ§Ã£o

ğŸš€ Tecnologias Utilizadas

Python 3.10+

FastAPI

Uvicorn

Google Generative AI (Gemini API)

Transformers (GPT2 Tokenizer)

python-dotenv

CORS Middleware

ğŸ“ Estrutura do Projeto
OtimizaIA-backend/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.py


O arquivo main.py contÃ©m todo o backend funcional.

ğŸ”‘ VariÃ¡veis de Ambiente

Crie um arquivo .env na raiz do projeto:

GEMINI_API_KEY=COLOQUE_SUA_CHAVE_AQUI

ğŸ§± InstalaÃ§Ã£o
1ï¸âƒ£ Criar ambiente virtual

Windows (PowerShell)

python -m venv venv
venv\Scripts\activate


Linux/Mac

python3 -m venv venv
source venv/bin/activate

2ï¸âƒ£ Instalar dependÃªncias

Se tiver requirements.txt:

pip install -r requirements.txt


Ou instale manualmente:

pip install fastapi uvicorn
pip install python-dotenv
pip install google-generativeai
pip install transformers

â–¶ Rodando o servidor
uvicorn main:app --reload


A API ficarÃ¡ disponÃ­vel em:

http://127.0.0.1:8000

ğŸ“˜ DocumentaÃ§Ã£o interativa:

Swagger UI â†’ http://127.0.0.1:8000/docs

ReDoc â†’ http://127.0.0.1:8000/redoc

ğŸ” Endpoints
ğŸ”¹ POST /analise

Analisa o texto enviado e retorna:

Prompt otimizado

Partes desnecessÃ¡rias

Tokens antes/depois

Consumo de Ã¡gua e energia

Economia total

ğŸ“¤ Exemplo de requisiÃ§Ã£o:
{
  "texto": "OlÃ¡, por favor, serÃ¡ que vocÃª poderia me explicar gentilmente o que Ã© um Ã¡tomo?"
}

ğŸ“¥ Exemplo de resposta:
{
  "analise": {
    "prompt_original": "OlÃ¡, por favor...",
    "prompt_otimizado": "Explique o que Ã© um Ã¡tomo.",
    "partes_desnecessarias": ["OlÃ¡", "por favor", "gentilmente"]
  },
  "metricas": {
    "tokens": {
      "antes": 40,
      "depois": 12,
      "economia": 28
    },
    "consumo_agua_ml": {
      "antes": 1.6,
      "depois": 0.48,
      "economia": 1.12
    },
    "consumo_energia_wh": {
      "antes": 0.16,
      "depois": 0.048,
      "economia": 0.112
    }
  }
}

ğŸ§  Como o backend funciona internamente
ğŸ”¹ 1. Conta tokens usando GPT2Tokenizer

Isso simula o tamanho real do prompt.

ğŸ”¹ 2. Calcula consumo ambiental

Com base nos tokens:

Ãgua: 0.04 ml por token

Energia: 0.004 Wh por token

ğŸ”¹ 3. Envia o texto ao Gemini

Com instruÃ§Ãµes rÃ­gidas para retornar JSON formatado.

ğŸ”¹ 4. Trata falhas da API

Se o Gemini retornar formato invÃ¡lido ou falhar, o backend:

NÃ£o quebra

Retorna o prompt original

Informa erro na anÃ¡lise inteligente

ğŸ“¦ Atualizar dependÃªncias

ApÃ³s instalar novas libs:

pip freeze > requirements.txt

ğŸ›‘ Encerrar servidor
CTRL + C


E para sair do ambiente virtual:

deactivate